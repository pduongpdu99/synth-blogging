[
  {
    "id": 1,
    "slug": "algorithmic-composition",
    "title": "Algorithmic Composition: When Code Meets Melody",
    "excerpt": "Exploring how programming concepts can be applied to create beautiful musical compositions using mathematical patterns and recursive structures.",
    "content": "# Algorithmic Composition: When Code Meets Melody\n\nMusic and mathematics have always been intertwined. From the mathematical ratios that define musical intervals to the complex patterns found in Bach's fugues, there's a deep connection between logical structures and beautiful melodies.\n\n## The Beauty of Mathematical Music\n\nWhen we think about music from a programmer's perspective, we start to see patterns everywhere:\n\n- **Recursion** in musical phrases that repeat with variations\n- **Loops** in rhythmic patterns and chord progressions  \n- **Functions** that transform melodies through transposition and inversion\n- **Data structures** in the way harmonies are built and resolved\n\n## Building a Simple Melody Generator\n\nLet's explore how we can use code to generate music. Here's a simple Python example:\n\n```python\nimport random\nfrom music21 import stream, note, duration\n\ndef generate_melody(scale, length=8):\n    melody = stream.Stream()\n    \n    for i in range(length):\n        # Choose a random note from the scale\n        pitch = random.choice(scale)\n        \n        # Add some rhythmic variation\n        dur = random.choice([0.5, 1.0, 1.5])\n        \n        # Create and add the note\n        n = note.Note(pitch, quarterLength=dur)\n        melody.append(n)\n    \n    return melody\n\n# C Major scale\nc_major = ['C4', 'D4', 'E4', 'F4', 'G4', 'A4', 'B4', 'C5']\nmy_melody = generate_melody(c_major)\n```\n\n## Advanced Techniques\n\nAs we dive deeper, we can explore more sophisticated approaches:\n\n### Markov Chains for Style Imitation\nBy analyzing existing compositions, we can build Markov chains that capture the statistical patterns of different composers and generate new music in their style.\n\n### Genetic Algorithms for Evolution\nWe can use evolutionary algorithms to \"breed\" melodies, selecting the most pleasing combinations and mutating them to create new variations.\n\n### Neural Networks for Deep Learning\nModern AI approaches can learn complex musical patterns from vast datasets, generating surprisingly human-like compositions.\n\n## The Philosophy of Algorithmic Art\n\nThere's something profound about using logic to create beauty. It challenges our notions of creativity and asks fundamental questions:\n\n- Can a computer truly be creative?\n- What role does randomness play in art?\n- How do we balance structure with spontaneity?\n\n## Conclusion\n\nAlgorithmic composition isn't about replacing human creativity—it's about augmenting it. By understanding the mathematical foundations of music, we can create new tools for expression and discover patterns we might never have found otherwise.\n\nThe intersection of code and melody opens up infinite possibilities. Every algorithm is a new instrument, every data structure a new way of thinking about harmony.\n\n*What will you compose with code?*",
    "date": "2024-01-15",
    "category": "Computer Science",
    "tags": [
      "Algorithms",
      "Music Theory",
      "Python"
    ],
    "readTime": "8 min read",
    "language": "en",
    "author": "Synth",
    "published": true
  },
  {
    "id": 2,
    "slug": "guitar-tuning-algorithms",
    "title": "Guitar Tuning Algorithms: Perfect Pitch Through Code",
    "excerpt": "Building a digital tuner using Fast Fourier Transform and frequency analysis to achieve perfect guitar tuning.",
    "content": "# Guitar Tuning Algorithms: Perfect Pitch Through Code\n\nEvery guitarist knows the frustration of an out-of-tune instrument. But what if we could build the perfect digital tuner using signal processing and algorithms?\n\n## The Science of Sound\n\nSound is vibration, and vibration can be measured. When you pluck a guitar string, it creates a complex waveform with a fundamental frequency and harmonics. Our job is to extract that fundamental frequency and compare it to the target pitch.\n\n## Fast Fourier Transform: The Magic Behind Frequency Detection\n\nThe FFT is our primary tool for converting time-domain audio signals into frequency-domain data:\n\n```javascript\n// Simplified FFT-based pitch detection\nfunction detectPitch(audioBuffer, sampleRate) {\n    const fftSize = 2048;\n    const fft = new FFT(fftSize);\n    \n    // Apply window function to reduce spectral leakage\n    const windowed = applyHammingWindow(audioBuffer);\n    \n    // Perform FFT\n    const spectrum = fft.forward(windowed);\n    \n    // Find the peak frequency\n    const peakIndex = findPeakFrequency(spectrum);\n    const frequency = (peakIndex * sampleRate) / fftSize;\n    \n    return frequency;\n}\n```\n\n## Building a Real-Time Tuner\n\nCreating a responsive tuner requires several components working together:\n\n### 1. Audio Input Processing\nWe need to capture audio from the microphone and process it in real-time chunks.\n\n### 2. Frequency Analysis\nUsing FFT to convert audio samples into frequency data.\n\n### 3. Pitch Detection\nIdentifying the fundamental frequency from the spectrum.\n\n### 4. Note Recognition\nConverting frequency to musical notes and calculating cents deviation.\n\n## The Mathematics of Musical Tuning\n\nStandard guitar tuning uses these frequencies:\n- E2: 82.41 Hz\n- A2: 110.00 Hz  \n- D3: 146.83 Hz\n- G3: 196.00 Hz\n- B3: 246.94 Hz\n- E4: 329.63 Hz\n\nThe relationship between notes follows the formula:\n`f = f₀ × 2^(n/12)`\n\nWhere f₀ is a reference frequency and n is the number of semitones.\n\n## Conclusion\n\nBuilding a guitar tuner combines signal processing, mathematics, and user interface design. It's a perfect example of how code can enhance our musical experience.\n\nThe next time you tune your guitar, remember the complex algorithms working behind the scenes to help you achieve perfect pitch. Technology and music, once again, in perfect harmony.",
    "date": "2024-01-10",
    "category": "Music Tech",
    "tags": [
      "DSP",
      "Guitar",
      "JavaScript"
    ],
    "readTime": "12 min read",
    "language": "en",
    "author": "Synth",
    "published": true
  },
  {
    "id": 3,
    "slug": "tao-nhac-bang-machine-learning",
    "title": "Tạo Nhạc Bằng Machine Learning",
    "excerpt": "Khám phá cách sử dụng trí tuệ nhân tạo để sáng tác nhạc, từ neural networks đến generative models trong âm nhạc.",
    "content": "# Tạo Nhạc Bằng Machine Learning\n\nTrí tuệ nhân tạo đang thay đổi cách chúng ta tạo ra và trải nghiệm âm nhạc. Từ việc sáng tác giai điệu đến việc tạo ra những bản nhạc hoàn chỉnh, machine learning mở ra những khả năng vô tận.\n\n## Âm Nhạc Như Dữ Liệu\n\nĐể máy tính có thể hiểu và tạo ra âm nhạc, chúng ta cần biểu diễn âm nhạc dưới dạng dữ liệu:\n\n- **MIDI**: Chuẩn giao tiếp nhạc cụ số\n- **Audio waveforms**: Dạng sóng âm thanh\n- **Symbolic notation**: Ký hiệu âm nhạc truyền thống\n- **Chord progressions**: Chuỗi hợp âm\n\n## Recurrent Neural Networks (RNN) cho Âm Nhạc\n\nRNN đặc biệt phù hợp với âm nhạc vì chúng có thể học các mẫu tuần tự:\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\n\ndef create_music_model(vocab_size, sequence_length):\n    model = tf.keras.Sequential([\n        LSTM(512, return_sequences=True, input_shape=(sequence_length, 1)),\n        Dropout(0.3),\n        LSTM(512, return_sequences=True),\n        Dropout(0.3),\n        LSTM(512),\n        Dense(256),\n        Dropout(0.3),\n        Dense(vocab_size, activation='softmax')\n    ])\n    \n    model.compile(\n        loss='categorical_crossentropy',\n        optimizer='adam',\n        metrics=['accuracy']\n    )\n    \n    return model\n```\n\n## Ứng Dụng Thực Tế\n\n### 1. Hỗ Trợ Sáng Tác\n- Gợi ý giai điệu và hợp âm\n- Tạo ra backing tracks\n- Phát triển ý tưởng âm nhạc\n\n### 2. Cá Nhân Hóa Âm Nhạc\n- Tạo nhạc phù hợp với sở thích cá nhân\n- Điều chỉnh theo tâm trạng\n- Tạo playlist thông minh\n\n### 3. Giáo Dục Âm Nhạc\n- Tạo bài tập luyện tập\n- Phân tích phong cách âm nhạc\n- Hỗ trợ học lý thuyết âm nhạc\n\n## Kết Luận\n\nMachine Learning không thay thế nghệ sĩ mà mở rộng khả năng sáng tạo của họ. Nó cung cấp những công cụ mới, những góc nhìn mới về âm nhạc.\n\nTương lai của âm nhạc sẽ là sự kết hợp hoàn hảo giữa cảm xúc con người và sức mạnh tính toán của máy móc. Đó là lúc rhythm thực sự meets logic.\n\n*Bạn sẽ sử dụng AI như thế nào trong hành trình âm nhạc của mình?*",
    "date": "2024-01-05",
    "category": "AI & Music",
    "tags": [
      "Machine Learning",
      "Âm nhạc",
      "TensorFlow"
    ],
    "readTime": "10 phút đọc",
    "language": "vi",
    "author": "Synth",
    "published": true
  },
  {
    "id": 4,
    "slug": "modular-synth-basics",
    "title": "Modular Synth Basics: Building Sound from Scratch",
    "excerpt": "An introduction to modular synthesis, explaining how oscillators, filters, and envelopes combine to create unique electronic sounds.",
    "content": "# Modular Synth Basics: Building Sound from Scratch\n\nModular synthesizers offer endless possibilities for sound design. Unlike fixed-architecture synths, modular systems let you connect components in any way you choose.\n\n## Key Modules\n\n- **Oscillators (VCOs)**: Generate raw waveforms (sine, saw, square)\n- **Filters (VCFs)**: Shape the timbre by removing or emphasizing frequencies\n- **Envelopes (ADSR)**: Control how sounds evolve over time\n- **LFOs**: Modulate parameters for movement and variation\n\n## Patching Example\n\nTo create a basic synth voice:\n1. Patch a VCO output to a VCF input\n2. Connect the VCF output to a VCA (amplifier)\n3. Use an envelope to control the VCA\n4. Trigger the envelope with a keyboard or sequencer\n\n## Creative Possibilities\n\nWith modular, you can:\n- Build generative music systems\n- Experiment with feedback and non-linear routing\n- Integrate digital and analog modules\n\n## Conclusion\n\nModular synthesis is about exploration. Every patch is a new instrument. Dive in and discover your own sonic universe.",
    "date": "2024-01-20",
    "category": "Music Tech",
    "tags": [
      "Synthesizer",
      "Modular",
      "Sound Design"
    ],
    "readTime": "7 min read",
    "language": "en",
    "author": "Synth",
    "published": true
  },
  {
    "title": "Test",
    "excerpt": "Test",
    "content": "Helo helo baby\n\n![1_Pf8Y1uhAN0RHy1sqG_qz5A.gif](/uploads/1755245048607_1_Pf8Y1uhAN0RHy1sqG_qz5A.gif)\n\nCó vẻ ổn",
    "category": "Computer Science",
    "tags": [
      "technology"
    ],
    "language": "en",
    "readTime": "1 min read",
    "date": "2025-08-15",
    "slug": "test",
    "featuredImage": "/uploads/1755245037063_1_Pf8Y1uhAN0RHy1sqG_qz5A.gif",
    "author": "Synth",
    "published": true,
    "id": 5
  },
  {
    "title": "am nhac",
    "excerpt": "am nhac",
    "content": "am nhac",
    "category": "Guitar Theory",
    "tags": [],
    "language": "vi",
    "readTime": "1 phút đọc",
    "date": "2025-08-19",
    "slug": "am-nhac",
    "featuredImage": "/uploads/1755626021409_functional-programming-music.png",
    "author": "Synth",
    "published": true
  }
]